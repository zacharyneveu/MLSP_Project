Traditional signal processing approaches can perform transcription for certain musical instruments and styles with a moderate level of success \cite{klapuri_signal_2004} . These approaches generally utilize the fact that a musical note is written as the lowest frequency ($F_0$) that occurs when this note is played. In the subtask of melody transcription, it is known that only one note can occur simultaneously, so simply finding the lowest prominent frequency in the time-frequency domain can often be adequate to transcribe a sample. In polyphonic transcription, however, multiple notes can be played at once. This problem can be approached well in a statistical context using \ac{MAP} estimation to determine the most likely combination of notes occurring given a set of frequencies \cite{emiya_multipitch_2010}. Another approach to polyphonic transcription is to factor the magnitude spectrogram of the signal. Because of the nature of the \ac{STFT}, the magnitude of each time-frequency bin must be non-negative, so non-negative matrix factorization has been applied by \cite{smaragdis_non-negative_2003}. For piano music, another known constraint is that representations are sparse in the frequency domain. To utilize this, \cite{bertin_blind_2007} used \ac{NKSVD} in the spectrogram domain to constrain the sparsity of solutions along with the positivity constraint. More recently, neural networks have been applied to the polyphonic transcription task, most notably in \cite{hawthorne_onsets_2018}. Neural network approaches are able to benefit from learning musical structure, grasping the nonlinear relationships between notes over time, making them the most performant approach for polyphonic transcription. Neural architectures suffer from the lack of large-scale labeled data in this area, however, so highly general networks for multiple instruments and styles do not exist.
